import os
from flask import Flask, request, jsonify, Response
from flask_cors import CORS
import google.generativeai as genai
from dotenv import load_dotenv

# --- Load biáº¿n mÃ´i trÆ°á»ng ---
load_dotenv()

app = Flask(__name__)

# --- Cáº¥u hÃ¬nh CORS (PhiÃªn báº£n Ä‘Æ¡n giáº£n hÃ³a) ---
# Cáº¥u hÃ¬nh nÃ y Ä‘Ã£ Ä‘á»§ cho Render vÃ  test local
CORS(
    app,
    origins=["https://e-book-for-me.web.app", "http://localhost:3000", "http://127.0.0.1:5500"],
    supports_credentials=True
)

# --- Cáº¥u hÃ¬nh Gemini API ---
try:
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if not gemini_api_key:
        raise ValueError("âš ï¸ GEMINI_API_KEY not found in environment variables.")
    
    genai.configure(api_key=gemini_api_key)
    print("âœ… Gemini API key loaded successfully.")

    # --- Sá»¬A Lá»–I TÃŠN MODEL ---
    # TÃªn model nÃ y Ä‘Æ°á»£c láº¥y tá»« log cá»§a báº¡n
    model = genai.GenerativeModel('gemini-flash-latest')
    print(f"âœ… Model '{model.model_name}' loaded successfully.")

    # (ÄÃ£ áº©n Ä‘i) Äoáº¡n code liá»‡t kÃª model, báº¡n cÃ³ thá»ƒ bá» comment náº¿u cáº§n debug
    # print("ğŸ“‹ Available models:")
    # for m in genai.list_models():
    #     if "generateContent" in m.supported_generation_methods:
    #         print(" -", m.name)

except Exception as e:
    print(f"âŒ Error configuring Gemini API: {e}")
    model = None


# --- Sá»¬A Lá»–I KHá»I Äá»˜NG Cá»¦A RENDER ---
# ThÃªm route trang chá»§ (/) Ä‘á»ƒ Render kiá»ƒm tra sá»©c khá»e (Health Check)
# NÃ³ sáº½ tráº£ lá»i 200 OK, bÃ¡o cho Render biáº¿t lÃ  "TÃ´i váº«n sá»‘ng!"
@app.route('/')
def health_check():
    return "Backend is running and healthy!", 200


# --- HÃ m sinh pháº£n há»“i stream ---
def generate_response_stream(prompt):
    if not model:
        print("âŒ generate_response_stream failed: Model is None.")
        yield "data: [ERROR] Lá»—i mÃ¡y chá»§: Model AI chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh.\n\n"
        return

    try:
        chat_session = model.start_chat(history=[])
        response_stream = chat_session.send_message(prompt, stream=True)

        for chunk in response_stream:
            if chunk.text:
                # MÃ£ hÃ³a láº¡i vÄƒn báº£n Ä‘á»ƒ trÃ¡nh lá»—i hiá»ƒn thá»‹ kÃ½ tá»±
                text_data = chunk.text.encode('utf-8').decode('utf-8')
                yield f"data: {text_data}\n\n"

    except Exception as e:
        print(f"âš ï¸ Error during generation: {e}")
        yield f"data: [ERROR] Xin lá»—i, cÃ³ lá»—i xáº£y ra tá»« AI: {str(e)}\n\n"


# --- API chÃ­nh ---
@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.json or {}
        user_message = data.get('message', '')
        conversation_history = data.get('conversation_history', [])
        document_content = data.get('document_content', '')
        dictionary_content = data.get('dictionary_content', '')
        language = data.get('language', 'vi')

        prompt = f"""
Báº¡n lÃ  má»™t trá»£ lÃ½ AI cho ná»n táº£ng e-learning.
HÃ£y tráº£ lá»i báº±ng {'Tiáº¿ng Viá»‡t' if language == 'vi' else 'English'}.

Lá»‹ch sá»­ trÃ² chuyá»‡n (Ä‘á»ƒ tham kháº£o):
{conversation_history}

Ná»™i dung tÃ i liá»‡u ngÆ°á»i dÃ¹ng Ä‘ang xem:
--- TÃ€I LIá»†U ---
{document_content}
--- Káº¾T THÃšC TÃ€I LIá»†U ---

Tá»« Ä‘iá»ƒn/Thuáº­t ngá»¯ tÃ¹y chá»‰nh:
--- Tá»ª ÄIá»‚N ---
{dictionary_content}
--- Káº¾T THÃšC Tá»ª ÄIá»‚N ---

Tin nháº¯n má»›i nháº¥t cá»§a ngÆ°á»i dÃ¹ng: "{user_message}"
"""
        # Tráº£ vá» stream data
        return Response(generate_response_stream(prompt), mimetype='text/event-stream')

    except Exception as e:
        print(f"âŒ Error in /chat endpoint: {e}")
        return jsonify({"error": "Lá»—i mÃ¡y chá»§ ná»™i bá»™."}), 500


# --- Cháº¡y local (Render sáº½ khÃ´ng dÃ¹ng khá»‘i nÃ y) ---
if __name__ == '__main__':
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port, debug=True)